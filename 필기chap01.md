# Chapter 1. 통계학의 개념과 역할

통계학은 단순히 숫자를 다루는 기술이 아니라,
**불확실한 상황에서 가장 합리적인 결정을 내리는 방법**을 연구하는 학문이다.

일상생활, 비즈니스, 의료, 금융 등 거의 모든 의사결정에서
부분적으로 수집된 정보로 전체를 판단해야 하므로
통계학은 필수적인 사고 도구다.

---

## 1.1 통계학이란 무엇인가?

통계학은 불완전한 정보, 불확실한 현상을 수량적으로 이해하는 과학이다.

- 전국 인구를 모두 조사하지 않고 일부 표본으로 전체를 추정하는 과정
- 유튜브 시청 패턴을 일부 데이터로 분석해 전체 경향을 읽는 과정
- 신약 임상시험에서 일부 환자만 테스트하는 과정

이 모든 것이 통계학의 활용이다.

통계학의 핵심은:

1) **부분(표본)을 보고 전체(모집단)를 추론하는 것**  
2) **불확실성을 수량화하는 것**  
3) **합리적인 의사결정을 설계하는 것**

---

## 1.2 기술통계 vs 추론통계

통계학은 크게 두 가지 분야로 나뉜다.

### ● 기술통계(Descriptive Statistics)
데이터를 있는 그대로 요약하고 설명하는 과정.

예:
- 평균, 중앙값, 최빈값
- 분산, 표준편차
- 히스토그램, 상자그림(Boxplot)
- 산점도(Scatter Plot)

기술통계는 “무슨 일이 일어났는가?”를 보여준다.

---

### ● 추론통계(Inferential Statistics)
표본 데이터를 이용해 모집단의 특성을 추정하고 가설을 검정하는 과정.

주요 기법:
- 신뢰구간(Confidence Interval)
- 가설검정(Hypothesis Testing)
- 표본분포(Sampling Distribution)
- 회귀분석(Regression)
- 분산분석(ANOVA)

추론통계는 “모집단에서는 어떤 일이 일어나는가?”를 예측한다.

---

## 1.3 모집단과 표본 (Population & Sample)

### ● 모집단(Population)
관심 있는 전체 집합  
예: 대한민국 모든 직장인의 연봉

### ● 표본(Sample)
모집단에서 추출한 일부 데이터  
예: 직장인 1,200명의 연봉 데이터

좋은 표본의 특징:
- **무작위성(randomness)**
- **대표성(representativeness)**
- **적절한 크기(sample size)**

표본이 나쁘면 어떤 고급 모델을 사용해도 잘못된 결론을 내리게 된다.

---

## 1.4 모수와 통계량 (Parameter & Statistic)

### ● 모수(Parameter)
모집단의 실제 값  
예: 전체 근로자의 평균 연봉 μ

### ● 통계량(Statistic)
표본에서 계산한 값  
예: 1,200명의 표본 평균 연봉 x̄

우리가 실제로 알 수 있는 것은 통계량뿐이며,
통계량을 이용해 모수를 추정하는 것이 통계학의 핵심 과정이다.

---

## 1.5 왜 통계학이 중요한가?

현대의 데이터는 대부분 **불완전하고 불확실하다**.

- 의료 데이터: 측정 오차, 결측치 존재
- 비즈니스 데이터: 일부 고객 행동만 기록
- 금융 데이터: 미래를 보장할 수 없음
- 설문 데이터: 응답 편향 발생 가능

통계학은 이런 한계를 극복하고
**제한된 자료로 신뢰할 수 있는 판단을 내릴 수 있게 해주는 도구**다.

---

## 1.6 통계학의 실제 활용 분야

### ● 비즈니스
- A/B 테스트
- 고객 세분화
- 마케팅 효과 분석

### ● 금융
- 리스크 관리(Value at Risk)
- 포트폴리오 최적화
- 사기 거래 탐지(Anomaly Detection)

### ● 의료
- 신약 임상시험
- 생존 분석
- 감염병 확산 모델링

### ● 제조
- 품질관리(QC)
- 공정 변화 탐지(Control Chart)

### ● 공공정책
- 설문조사 기반 의사결정
- 인구 구조 분석
- 교통량·수요 예측

---

## 1.7 통계학은 과학이자 예술이다

통계학은 수학적 분석을 바탕으로 하지만,
현실 문제를 모델링하고 해석하는 과정에서는 인간의 판단과 직관이 중요하다.

예:
- 어떤 변수를 선택할 것인가?
- 어떤 모델을 적용할 것인가?
- 결과를 어떻게 해석할 것인가?

따라서 통계학은 **계산 능력 + 해석 능력**이 동시에 필요한 분야이다.

---

## 1.8 ADP 시험에서 Chapter 1이 중요한 이유

Chapter 1의 개념은 ADP 필기 모든 영역의 기초가 된다.

- 가설검정 이해  
- 회귀분석 해석  
- 표본·모집단 구분  
- 추정과 오차의 의미  
- 데이터 분석의 사고방식  

기초가 단단해야 뒤의 심화 내용들이 자연스럽게 이해된다.

---

## ✔ Chapter 1 요약

- 통계는 '불확실성을 다루는 과학'이다.  
- 기술통계는 요약, 추론통계는 전체 추정이다.  
- 모집단/표본, 모수/통계량은 통계학의 출발점이다.  
- 현대 사회 거의 모든 분야에 통계학이 활용된다.  
- ADP 시험에서 필수 개념이다.




# Chapter 2. 확률의 기본 개념

확률은 불확실한 상황을 수량적으로 표현하는 가장 중요한 도구이다.  
통계학의 절반은 확률 개념을 이해하는 데서 시작한다고 해도 과언이 아니다.  
이 장에서는 확률의 기초와 조건부 확률, 독립성, 베이즈 정리를 직관적으로 정리한다.

---

## 2.1 표본공간과 사건

### ● 표본공간(Sample Space)
어떤 실험에서 **가능한 모든 결과의 집합**을 의미한다.

예:
- 주사위 → {1,2,3,4,5,6}
- 동전 → {앞, 뒤}
- 날씨 → {비, 흐림, 맑음}

### ● 사건(Event)
표본공간에서 관심 있는 부분집합.

예:
- "주사위가 짝수" → {2,4,6}
- "오늘 비가 온다" → {비}

사건은 결과들의 집합으로 표현된다는 점이 중요하다.

---

## 2.2 확률의 고전적 정의

확률을 가장 단순하게 정의하면:

\[
P(A) = \frac{\text{A가 발생하는 경우의 수}}{\text{전체 경우의 수}}
\]

예:
- 주사위에서 3이 나올 확률 = 1/6  
- 짝수가 나올 확률 = 3/6 = 1/2

이 정의는 사건이 모두 “동등하게 발생할 가능성이 있을 때” 사용된다.

---

## 2.3 확률의 공리적 정의 (Kolmogorov Axioms)

현대 확률론은 다음 세 가지 공리 위에서 완전히 정의된다.

1) **비음성**  
\[
P(A) \ge 0
\]

2) **표본공간의 확률은 1**
\[
P(S) = 1
\]

3) **상호배반(additive)**  
서로 동시에 일어날 수 없는 사건 A, B에 대하여
\[
P(A \cup B) = P(A) + P(B)
\]

이 공리는 복잡한 상황에서도 확률을 일관되게 계산하는 기반이 된다.

---

## 2.4 조건부 확률 (Conditional Probability)

조건부 확률은 **어떤 사건 B가 이미 발생했다는 조건에서 A가 발생할 확률**이다.

\[
P(A|B) = \frac{P(A \cap B)}{P(B)}
\]

### 예시로 이해하기
- 전체 학생 중 남학생 비율 = 60%  
- 농구부 중 남학생 비율 = 80%  

여기서 궁금한 것은  
“농구부(B)라는 조건에서 남학생(A)일 확률”  

즉,
\[
P(A|B)
\]

조건부 확률은  
**한 사건에 대한 불확실성이 다른 사건의 정보로 인해 변화**한다는 점이 핵심이다.

---

## 2.5 독립(Independence)

두 사건 A, B가 **독립**이라는 것은  
A가 일어났다는 사실이 B의 발생 확률에 아무 영향도 주지 않는다는 뜻이다.

수학적으로는:

\[
P(A \cap B) = P(A)P(B)
\]

### 직관적 예
- 동전의 앞뒤 결과는 이전 결과와 독립  
- 서로 모르는 두 사람이 같은 시간대에 전화를 걸 확률  
- 미세먼지 수치와 야구 경기 승패는 보통 독립

### 독립이 아닌 경우 예
- 비가 오는 날 교통량 증가  
- 학생의 공부 시간과 시험 점수  
- 고객의 연령대와 구매 패턴

독립 여부를 판단하는 것은 통계와 머신러닝에서 매우 중요한 개념이다.

---

## 2.6 전확률 정리 (Law of Total Probability)

사건 B가 여러 하위 사건으로 나눠질 때,
A의 확률은 전체 경우를 모두 고려하여 계산할 수 있다.

\[
P(A) = \sum_i P(A | B_i) P(B_i)
\]

### 예시
보험 회사는 가입자의 리스크를 여러 그룹(B₁, B₂, …)으로 나누어  
전체 사고 확률 P(A)를 계산한다.

---

## 2.7 베이즈 정리 (Bayes' Theorem)

베이즈 정리는 ADP 시험뿐 아니라  
의료검진, 금융 리스크, 머신러닝(특히 나이브 베이즈)에서 매우 중요한 공식이다.

\[
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
\]

### 쉬운 사례: 질병 검사 문제
- 질병 유병률: 1%
- 검사 정확도: 99%
- 위양성률: 5%

검사 결과가 “양성”이라고 나와도  
실제로 질병일 확률은 얼마일까?

직관은 “99%일 것 같다”라고 말하지만  
실제 계산하면 약 16% 정도밖에 되지 않는다.

이것이 바로 **희귀 사건에서의 베이즈 직관 붕괴**이다.

---

## 2.8 확률에서 자주 발생하는 실수들

### ● 1) 조건부 확률을 뒤집어 생각하는 오류
P(A|B)와 P(B|A)는 전혀 다른 값이다.

### ● 2) 희귀 사건에서 정확도 착시
민감도(sensitivity)와 특이도(specificity)를 혼동하는 경우가 많다.

### ● 3) 독립이라고 가정해버리는 오류
현실의 대부분 사건은 서로 영향을 주고받는다.

### ● 4) 베이스레이트(Base Rate) 무시
전체 확률(P(A))을 고려하지 않고 P(B|A)만 보고 판단하는 오류.

---

## 2.9 확률 사고를 기르는 방법

확률은 단순 계산능력보다 “사고방식"이 중요하다.

### ● 1) 사건을 표본공간으로 표현해보기  
모든 문제를 집합으로 표현하면 훨씬 명확해진다.

### ● 2) 다이어그램(베이즈 트리/벤 다이어그램) 사용  
문제의 구조가 눈에 보인다.

### ● 3) 실제 예시를 연결  
- 교통사고 확률  
- 게임에서 아이템 드랍 확률  
- 야구 타격률  
- 로또 확률

### ● 4) 조건부 확률은 항상 “조건 → 결과” 순으로 읽기  
표기 순서를 헷갈리면 오답으로 연결된다.

---

## ✔ Chapter 2 요약

- 확률은 불확실성을 정량화하는 도구이다.
- 표본공간은 모든 결과의 집합, 사건은 부분집합이다.
- 조건부 확률은 “조건이 주어진 상황에서의 확률”.
- 독립은 한 사건이 다른 사건의 확률에 영향을 주지 않는 것.
- 전확률 정리는 복잡한 확률을 전체 사건으로 분해하는 도구.
- 베이즈 정리는 ADP 시험 및 실무에서 매우 중요하다.
- 확률을 잘 이해하려면 집합적 사고·조건의 역할을 직관적으로 파악해야 한다.



# Chapter 3. 확률분포의 이해

확률분포는 불확실한 현상을 수학적으로 모델링한 것이다.  
현실의 수많은 사건들은 고유한 '패턴'을 갖고 있고,  
확률분포는 그 패턴을 수학적으로 표현한 결과물이다.

확률분포를 이해하는 것은 ADP 뿐 아니라  
추론통계, 회귀분석, 머신러닝의 기본을 구축하는 핵심 과정이다.

---

## 3.1 왜 확률분포가 중요한가?

확률분포를 알면 다음을 할 수 있다.

- 사건이 일어날 확률 계산
- 데이터가 특정 범위에 들어갈 확률 계산
- 평균·분산 추정
- 검정통계량(t, F, χ²)의 분포 해석
- 회귀계수의 신뢰구간 계산
- 시뮬레이션(몬테카를로) 기반 분석
- 머신러닝 모델의 확률적 해석

즉, 확률분포는 **데이터의 구조를 수학적으로 이해하기 위한 언어**다.

---

# 🔷 이산형 분포 vs 연속형 분포

확률분포는 크게 두 가지로 나뉜다.

| 구분 | 설명 | 예 |
|------|--------|---------|
| **이산형 분포** | 값이 “끊어져 있는” 정수 값 | 베르누이, 이항, 포아송 |
| **연속형 분포** | 값이 연속적인 실수 범위 | 정규, t, 카이제곱, F |

---

# -------------------------
# 🟥 3.2 베르누이 분포 (Bernoulli)
# -------------------------

베르누이 분포는 확률분포 중 가장 단순하지만 가장 기본이 되는 분포다.

### ● 정의  
성공(1) 또는 실패(0)의 두 결과만 가지는 실험.

\[
P(X=1)=p,\quad P(X=0)=1-p
\]

### ● 예
- 고객이 구매(1)/비구매(0)
- 동전 앞/뒤
- 특정 단어 포함 여부(1/0)

### ● 평균과 분산

\[
E(X)=p, \quad Var(X)=p(1-p)
\]

베르누이 분포는  
모든 이항분포·로지스틱 회귀·딥러닝의 Cross-Entropy까지  
수많은 알고리즘의 기초가 된다.

---

# -------------------------
# 🟥 3.3 이항분포 (Binomial)
# -------------------------

이항분포는 **베르누이 시행을 n번 반복했을 때 성공 횟수**의 분포이다.

\[
X \sim Bin(n,p)
\]

### ● 예
- 20명의 고객 중 구매 고객 수  
- 10개 부품 검사 중 불량품 수  
- 서버에서 1분 동안 성공 처리된 요청 수(성공률 고정 가정)

### ● 평균과 분산

\[
E(X)=np,\quad Var(X)=np(1-p)
\]

### ● 직관  
이항분포의 핵심은 **독립적 반복**이라는 점이다.  
이 가정이 깨지면 더 이상 순수 이항분포가 아니다.

예:  
고객 간 추천 효과가 있는 경우 → 독립성 X → 다른 모델 필요

---

# -------------------------
# 🟥 3.4 포아송 분포 (Poisson)
# -------------------------

포아송 분포는 **드문 사건의 발생 횟수**를 모델링한다.

### ● 예
- 하루 평균 2건의 교통사고
- 서버 오류 발생 횟수
- 한 시간 동안 콜센터에 걸려오는 전화 수
- 매장 방문 고객 수

\[
X \sim Poi(\lambda)
\]

### ● 특징  
- 평균과 분산이 모두 λ  
- 희귀 사건에서 자주 등장  
- 이항분포의 극한 형태 (n → ∞, p → 0, np = λ)

### ● 직관  
‘희귀하지만 발생 가능성이 완전히 0은 아닌 사건’을 모델링할 때 사용한다.

---

# -------------------------
# 🟥 3.5 연속형 확률분포
# -------------------------

연속형 분포는 값이 실수 범위를 가지며,  
확률은 ‘확률밀도함수(PDF)’로 표현된다.

---

# 🟦 3.5.1 정규분포 (Normal Distribution)

정규분포는 통계학의 중심이다.

\[
X \sim N(\mu, \sigma^2)
\]

### ● 특징
- 평균 μ를 중심으로 대칭  
- 자연 현상의 대부분이 정규분포 형태  
- 중심극한정리(CLT)에 의해 표본평균의 분포가 정규로 수렴  
- 회귀, ANOVA, 가설검정의 기본 가정

### ● 예
- 키, 체중
- 시험 점수
- 기계 제품 측정값
- 금융수익률(단기에서는 정규 근사 가능)

### ● 표준정규분포  

\[
Z = \frac{X - \mu}{\sigma}
\]

모든 정규분포는 Z로 변환하여 표준화할 수 있다.

---

# 🟦 3.5.2 t-분포

t-분포는 **모분산을 모르는 상황에서 평균 추론을 할 때** 사용된다.

### ● 특징  
- 표본수가 작을 때 꼬리가 두꺼움  
- n이 커질수록 정규분포에 수렴  
- t-검정의 기반

### ● 직관  
데이터가 적으면 평균 추정에 불확실성이 커지므로  
정규보다 더 두꺼운 꼬리를 가져야 한다.

---

# 🟦 3.5.3 카이제곱(χ²) 분포

카이제곱 분포는 **분산의 분포**이다.

### ● 주요 용도
- 분산 추정
- 적합도 검정(Goodness of Fit)
- 독립성 검정(교차표)

### ● 특징
- 오른쪽 꼬리가 김  
- 자유도가 커질수록 정규 근사 가능

---

# 🟦 3.5.4 F-분포

F-분포는 **두 분산의 비율**의 분포다.

\[
F = \frac{\chi^2_1 / df_1}{\chi^2_2 / df_2}
\]

### ● 사용처
- 분산분석(ANOVA)
- 회귀모형 유의성 검정

F-분포는 비교의 분포, 즉 “두 집단 간 변동의 비율”을 분석하는 데 사용된다.

---

# -------------------------
# 🟥 3.6 ACF와 PACF의 개념적 등장 (간단 사전 맛보기)
# -------------------------
(시계열은 이후 Chapter 9에서 상세히 다룸)

확률분포 개념을 시계열로 확장하면  
데이터가 시간에 따라 어떻게 변화하는지를 모형화할 수 있다.

- ACF: 시차별 전체 상관관계  
- PACF: 중간 효과를 제거한 순수 상관

AR/MA/ARIMA 모델을 이해하는 데 확률분포 개념이 필수다.

---

# -------------------------
# 🟥 3.7 확률분포 선택의 사고방식
# -------------------------

### ● 1) 데이터가 이산형인가 연속형인가?
- 구매 수: 이산형 → 베르누이/이항/포아송
- 체중: 연속형 → 정규

### ● 2) 값이 0~1 사이인가?  
→ Beta 분포 활용 (추후 Bayesian 분석에서 필요한 내용)

### ● 3) 꼬리가 두꺼운가?  
→ t-분포, 로그정규 분포 등 고려

### ● 4) 시간의 영향을 받는가?  
→ 시계열 모델 필요

### ● 5) 드문 사건인가?  
→ 포아송 적합

---

## ✔ Chapter 3 요약

- 확률분포는 ‘현상의 패턴’을 수학적으로 표현한 것  
- 베르누이 → 1/0 사건  
- 이항 → 여러 번의 성공 횟수  
- 포아송 → 드문 사건  
- 정규분포 → 자연·사회 현상에 가장 자주 등장  
- t, χ², F는 추론통계의 핵심 도구  
- 확률분포를 정확히 이해해야 가설검정·회귀·시계열 모두 수월해진다



# Chapter 4. 기술통계의 심화 이해

기술통계(Descriptive Statistics)는 데이터를 바라보는 첫 단계이자,
추론통계·머신러닝 모델링 이전에 반드시 검토해야 하는 필수 과정이다.

이 장에서는 평균·분산 같은 기본 요약뿐 아니라,
데이터의 전체 구조를 파악하는 데 필요한 통찰을 얻는 방법을 집중적으로 다룬다.

---

# 🟥 4.1 기술통계란 무엇인가?

기술통계의 목표는 단순하다.

> **“데이터를 이해 가능한 형태로 요약하고 구조를 드러내는 것.”**

데이터 분석에서 기술통계를 건너뛰는 것은  
지도 없이 산속에 들어가는 것과 같다.

기술통계는 다음을 이해하는 데 중요한 역할을 한다.

- 데이터가 어떤 분포를 갖는가?
- 대표값(평균, 중앙값)은 어떤가?
- 산포(변동성)는 큰가 작은가?
- 이상치가 존재하는가?
- 범주는 몇 개이고 빈도는 어떻게 되는가?
- 데이터의 형태가 모델링에 적합한가?

---

# 🟥 4.2 중심경향성 (Measures of Central Tendency)

데이터의 “중심”을 나타내는 수치들이다.

---

## 🔷 4.2.1 평균(Mean)

\[
\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i
\]

평균은 가장 널리 사용되며 계산도 쉽지만, **이상치(outlier)에 매우 민감**하다.

예:
- 연봉 데이터에서 몇몇 억대 연봉자가 평균을 크게 끌어올림

---

## 🔷 4.2.2 중앙값(Median)

데이터를 크기순으로 정렬했을 때 정중앙에 있는 값.

장점:
- 이상치의 영향을 거의 받지 않는다.
- 소득, 집값처럼 편향된 분포를 설명할 때 유리.

예:
- 평균 연봉: 5,500만원  
- 중앙값 연봉: 3,800만원  

중앙값이 훨씬 현실적인 지표일 수 있다.

---

## 🔷 4.2.3 최빈값(Mode)

가장 자주 등장하는 값.

범주형 데이터에서 중요하며,  
제품 구매 유형, 교통수단, 고객 성별 등에서 자주 사용된다.

---

# 🟥 4.3 산포도(Variability, Dispersion)

“값들이 얼마나 퍼져 있는가”를 측정하는 지표.

---

## 🔷 4.3.1 분산(Variance)과 표준편차(Standard Deviation)

\[
Var(X)=\frac{1}{n-1}\sum (x_i - \bar{x})^2
\]

표준편차는 분산의 제곱근이다.

\[
sd(X)=\sqrt{Var(X)}
\]

표준편차가 큰 데이터:
- 매우 다양한 값 존재  
- 변동성이 큼  
- 예측 어려움 증가  

---

## 🔷 4.3.2 사분위수(Quartile)와 IQR

### ● Q1  
25% 지점  
### ● Q2 (중앙값)  
50% 지점  
### ● Q3  
75% 지점  
### ● IQR (Interquartile Range)  
\[
IQR = Q3 - Q1
\]

IQR은 분포의 중심 50%가 얼마나 넓게 퍼져 있는지 알려준다.

---

# 🟥 4.4 왜도(Skewness)와 첨도(Kurtosis)

데이터의 형태를 더 깊이 이해하기 위한 지표다.

---

## 🔷 4.4.1 왜도(Skewness)

분포의 비대칭 정도를 나타낸다.

- **양의 왜도(오른쪽 꼬리)**  
  예: 소득, 집값, 수명  
- **음의 왜도(왼쪽 꼬리)**  
  예: 시험에서 대부분 만점에 가까운 점수

직관:

- 왜도 > 0 → 높은 값들이 일부 튀어나와 있음  
- 왜도 < 0 → 낮은 값들에 극단치 존재 가능  

---

## 🔷 4.4.2 첨도(Kurtosis)

분포의 **꼬리 두께(tail heaviness)**를 의미한다.

- 첨도 < 3 : 꼬리가 얇음 (평평함)  
- 첨도 = 3 : 정규분포  
- 첨도 > 3 : 꼬리가 두꺼움 (극단치 발생 가능성↑)

금융 데이터는 대체로 높은 첨도를 가진다 → 극단적인 변동 가능성 존재.

---

# 🟥 4.5 이상치(Outlier) 탐지

이상치는 분석 결과에 강한 영향을 미칠 수 있기 때문에 반드시 탐지해야 한다.

### ● Boxplot 기준  
- Q1 − 1.5 × IQR  
- Q3 + 1.5 × IQR  
이 범위를 벗어나면 이상치로 간주.

### ● Z-Score 기준  
\[
Z = \frac{x - \bar{x}}{s}
\]

|Z| > 3 → 이상치 가능성 높음

### ● 실무적 고려
이상치는 제거하는 것이 아니라  
“왜 발생했는지”를 먼저 고민해야 한다.

- 데이터 입력 오류인가?  
- 실제 특이한 사건인가?  
- 측정 장비 오류인가?  

이상치를 무조건 제거하는 것은 위험할 수 있다.

---

# 🟥 4.6 분포 시각화

기술통계에서는 시각화가 매우 중요하다.

---

## 🔷 4.6.1 히스토그램(Histogram)

연속형 데이터의 분포를 이해하는 가장 기본적인 방법.

기억해야 할 포인트:
- bin 크기에 따라 분포 모양이 크게 달라진다  
- 데이터가 정규분포에 가까운지 시각적으로 파악 가능  
- 왜도·첨도 판단 가능  

---

## 🔷 4.6.2 Boxplot (상자그림)

- 중앙값  
- IQR  
- 이상치  
- 데이터의 대칭성  

을 한 번에 확인 가능하기 때문에 자주 사용됨.

비교 분석(여러 그룹 비교)에 특히 효과적이다.

---

## 🔷 4.6.3 산점도(Scatter Plot)

두 변수 간 관계를 시각적으로 확인한다.

예:
- 공부 시간 vs 시험 점수  
- 광고비 vs 매출  
- 나이 vs 소득  

산점도는 **회귀분석을 하기 전에 반드시** 확인해야 한다.

---

# 🟥 4.7 데이터의 형태(Shape) 분석

데이터의 전체 구조를 파악하는 것은  
모든 모델링의 출발점이다.

확인해야 할 질문들:

- 대칭적인가? 비대칭인가?
- 꼬리가 두꺼운가?
- 단봉형인가? 또는 여러 개의 봉우리가 존재하는가?
- 데이터가 그룹(클러스터)처럼 보이는가?

예:
- 시험 점수는 종종 양쪽 꼬리가 두꺼움 → 부정행위, 난이도 문제  
- 고객 데이터는 군집 구조를 가짐 → 세그먼트 존재  

---

# 🟥 4.8 기술통계를 잘하면 좋은 점

기술통계를 제대로 하면 다음 과정이 훨씬 쉬워진다.

- 모델 선택  
- 변수 선택  
- 데이터 정제  
- 이상치 처리  
- 정규성 검토  
- 스케일링 필요 여부 판단  

즉, 기술통계는 **모든 분석 과정의 품질을 결정하는 핵심 기반**이다.

---

## ✔ Chapter 4 요약

- 기술통계는 데이터 분석의 출발점이자 필수 단계  
- 평균·중앙값·최빈값은 대표값 요약  
- 분산·표준편차·IQR은 산포를 알려줌  
- 왜도·첨도는 분포의 형태를 직접적으로 파악  
- 이상치는 제거보다 “이해”가 먼저  
- 히스토그램, 박스플롯, 산점도는 기본 도구  
- 기술통계를 잘하면 모델링의 절반이 해결된다



# Chapter 5. 표본분포(Sampling Distribution)의 이해

표본분포는 통계학에서 가장 중요한 개념 중 하나이며,  
가설검정, 신뢰구간, 회귀분석의 이론적 기반이 된다.

표본분포는 다음 질문에 답하기 위해 존재한다:

> “똑같은 표본조사를 여러 번 반복하면 표본평균은 어떻게 변할까?”

이 질문에 대한 이해가 부족하면  
t-검정·신뢰구간·회귀계수 해석을 할 때 계속 막히게 된다.

---

# 🟥 5.1 표본분포란 무엇인가?

표본분포(sampling distribution)는 다음과 같은 개념이다.

- 모집단에서 **동일한 크기의 표본을 여러 번 추출**하고  
- 각 표본에서 계산된 통계량(평균, 비율 등)의 **분포**

예를 들어,  
대한민국 성인의 키 height에 대해  
*100명을 10번 뽑았다면*  
→ 10개의 표본평균이 존재한다.

이 10개의 평균이 모여 만드는 분포가 ‘표본평균의 표본분포’다.

실제로는 무한히 많은 표본을 추출할 수 있다고 가정한다.

---

# 🟥 5.2 왜 표본분포가 필요한가?

통계학의 목적은 **모집단을 추정**하는 것이다.

문제는…

우리가 실제로 관측할 수 있는 것은 **표본 하나뿐**이라는 점이다.

그렇다면:

- 이 표본이 “우연히 특별한” 표본일까?
- 아니면 “평범한” 표본일까?
- 우리가 얻은 평균은 얼마나 신뢰할 수 있을까?
- 표본 크기가 커지면 얼마나 안정적일까?

이 질문들에 답할 수 있게 해주는 것이 **표본분포**다.

---

# 🟥 5.3 표본평균의 표본분포

가장 중요한 표본분포는 **표본평균의 분포**이다.

표본평균 x̄의 평균과 분산은 다음과 같다.

### ● 평균
\[
E(\bar{x}) = \mu
\]

표본평균의 기대값은 **모집단 평균과 동일**하다.  
→ 표본평균은 모집단 평균의 ‘불편추정량’이다.

### ● 분산
\[
Var(\bar{x}) = \frac{\sigma^2}{n}
\]

표본 크기 n이 커질수록 변동성이 줄어든다.

이는 다음 실제적 사실을 의미한다:

- 표본 크기가 2배 → 평균의 오차는 1/√2  
- 표본 크기가 4배 → 오차는 절반  
- 표본 크기가 9배 → 오차는 1/3

---

# 🟥 5.4 표준오차(Standard Error, SE)

표준오차는 표본평균의 “표준편차”이다.

\[
SE = \frac{\sigma}{\sqrt{n}}
\]

### ● 표준오차가 작으면?
- 표본평균이 안정적  
- 신뢰구간이 좁아짐  
- 가설검정에서 더 작은 변화도 감지 가능  

### ● 표준오차가 크면?
- 표본 평균이 들쭉날쭉  
- 신뢰구간이 넓어짐  
- 통계적 유의성 판단이 어려움

표준오차는 ADP 필기에서도 매우 자주 등장한다.

---

# 🟥 5.5 중심극한정리 (Central Limit Theorem)

표본분포를 이해하는 데 가장 중요한 정리.

\[
n \ge 30 \text{ 이면 표본평균이 정규분포에 가까워진다.}
\]

중심극한정리의 핵심은:

> 모집단의 형태가 어떻든 (정규든 아니든)  
> 표본평균의 분포는 정규에 가까워진다.

---

## 🔷 중심극한정리가 주는 실제적 힘

1) 모집단이 오른쪽으로 긴 꼬리를 가진 분포라도  
→ n이 충분히 크면 x̄는 정규분포를 따른다.

2) 신뢰구간을 만들 수 있다.  
3) 가설검정을 수행할 수 있다.  
4) 회귀분석에서 계수의 분포를 정규로 가정할 수 있다.

즉, 현대 통계학의 대부분이  
이 정리를 바탕으로 돌아간다.

---

# 🟥 5.6 표본비율의 표본분포

비율 p̂ = X/n 의 분포는 다음과 같다.

\[
E(\hat{p}) = p
\]

\[
Var(\hat{p}) = \frac{p(1-p)}{n}
\]

이는 설문·투표·마케팅 분석 등에서 매우 자주 사용된다.

예:
- 고객 중 구매 의사 비율  
- 선거 후보 지지율  
- 광고 클릭률(CTR)

표본비율은 조건이 맞으면 정규분포로 근사 가능하다.

---

# 🟥 5.7 큰 수의 법칙 (Law of Large Numbers)

표본평균은 표본 크기가 커지면 모집단 평균 μ에 가까워진다.

\[
\bar{x} \to \mu  \quad (n \to \infty)
\]

직관적 예:
- 동전을 5번 던지면 → 3:2, 4:1 등 불안정  
- 동전을 5000번 던지면 → 거의 1:1

큰 수의 법칙은 안정성의 원리를 제공한다.

---

# 🟥 5.8 표본분포를 왜 강조하는가?

다음 개념들이 모두 표본분포 위에서 작동한다:

- 신뢰구간  
- t-검정·z-검정  
- 회귀계수의 표준오차  
- ANOVA의 F-통계량  
- 머신러닝에서의 추정량 분포

표본분포의 이해 없이는  
추론통계 전반, 특히 ADP 실기에서도  
“왜 이런 계산이 필요한지” 이해할 수 없다.

---

# ✔ Chapter 5 요약

- 표본분포는 표본을 반복적으로 추출했을 때 통계량들이 만드는 분포  
- 표본평균은 불편추정량이며 분산은 σ²/n  
- 표준오차(SE)는 추정량의 변동성을 나타냄  
- 중심극한정리는 표본평균이 정규분포를 따른다는 강력한 사실을 제공  
- 큰 수의 법칙은 표본평균이 모집단 평균에 수렴함을 보장  
- 신뢰구간·가설검정·회귀 분석은 모두 표본분포 개념 위에서 작동

