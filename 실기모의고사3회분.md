ADP 실기 모의고사 1회차 (실전 난이도 동일)
📂 사용 데이터셋 (다운로드 없이 사용 가능)
customers.csv
customers <- read.csv(text = "
id,age,gender,income,visit_count,purchase,region,score
1,25,F,3200,5,1,East,80
2,45,M,5500,3,0,West,60
3,33,F,4000,4,1,South,75
4,50,M,6200,2,0,East,55
5,29,F,3500,6,1,North,78
6,41,M,4800,3,0,West,62
7,37,F,4200,5,1,North,82
8,52,M,6800,1,0,South,58
9,31,F,3900,4,1,East,74
10,47,M,5100,2,0,West,61
")

📝 ADP 실기 모의고사 1회차 문제 (총 15문항)
문제 1. 결측치 처리

income 변수에 결측이 있다고 가정하고, 중앙값으로 대체하는 R 코드를 작성하라.

문제 2. 파생변수 생성

방문 대비 구매전환율

𝑐
𝑜
𝑛
𝑣
𝑒
𝑟
𝑠
𝑖
𝑜
𝑛
=
𝑝
𝑢
𝑟
𝑐
ℎ
𝑎
𝑠
𝑒
𝑣
𝑖
𝑠
𝑖
𝑡
_
𝑐
𝑜
𝑢
𝑛
𝑡
conversion=
visit_count
purchase
	​


을 생성하라.

문제 3. 범주형 변수 요약

지역(region)별 평균 score 를 요약하라.

문제 4. 상관분석

age, income, score 간 피어슨 상관계수를 계산하라.

문제 5. 가설검정(t-test)

성별(gender)에 따라 score 평균 차이가 있는지 단측 t-test를 수행하라.
대립가설: 여성 > 남성

문제 6. 로지스틱 회귀

purchase 를 종속변수로 하고
(age, income, score)를 설명변수로 하여 로지스틱 회귀 모델을 구성하고,
score의 오즈비(odds ratio)를 해석하라.

문제 7. 다중공선성(VIF)

위 모델의 VIF를 계산하라.

문제 8. 의사결정나무 모델

purchase 예측을 위한 rpart 모델을 생성하고,
가장 중요한 변수를 적어라.

문제 9. 군집 분석(K-means)

age, income, score 를 사용하여 K=2 클러스터링을 수행하라.
두 군집의 중심값을 제시하라.

문제 10. PCA 분석

age, income, score 3변수에 대해
PCA를 수행하고 PC1의 설명력(%)을 구하라.

문제 11. 시계열 데이터 생성

아래 월별 판매량을 ts() 객체로 생성하라. (frequency=12)

sales <- c(200,210,250,270,300,330,350,380,360,400,420,450)

문제 12. ARIMA 예측

위 시계열로 auto.arima 모델을 적합하고
향후 3개월을 예측하라.

문제 13. 텍스트 마이닝

다음 문장에서 stopword 제거 후 단어를 토큰화하라.

“Data science is an exciting and rapidly growing field”

문제 14. 품질관리(Cp, Cpk)

평균=10, 표준편차=0.15, 규격 LSL=9.5, USL=10.5 일 때
Cp와 Cpk를 계산하고 공정 상태를 해석하라.

문제 15. Confusion Matrix 해석

정확도 Accuracy와 재현율 Recall의 차이를 서술하라.

📘 정답 및 해설 — 모의고사 1회차
1번 정답
customers$income[is.na(customers$income)] <- median(customers$income, na.rm=TRUE)


해설: 중앙값 대체는 robust하며 분포 왜곡을 최소화한다.

2번 정답
customers$conversion <- customers$purchase / customers$visit_count

3번 정답
aggregate(score ~ region, data=customers, mean)

4번 정답
cor(customers[, c("age","income","score")])

5번 정답 (단측 t-test)
t.test(score ~ gender, data=customers, alternative="greater")


해설: p < 0.05면 여성 점수가 유의하게 높음.

6번 정답
fit <- glm(purchase ~ age + income + score,
           data=customers, family="binomial")
exp(coef(fit))  # odds ratio


해석 예시(모범 답안):

score의 OR이 1.08이라면, score가 1 증가할 때 구매 확률의 오즈가 8% 증가함을 의미한다.

7번 정답
library(car)
vif(fit)


해석: VIF > 10이면 강한 다중공선성.

8번 정답
library(rpart)
tree <- rpart(purchase ~ ., data=customers)
tree$variable.importance


가장 중요한 변수: score 또는 income (데이터에 따라 다름)

9번 정답
k <- kmeans(customers[, c("age","income","score")], centers=2)
k$centers

10번 정답
p <- prcomp(customers[, c("age","income","score")], scale.=TRUE)
summary(p)


출력의 Proportion of Variance 첫 번째 값이 PC1 설명력.

11번 정답
ts_sales <- ts(sales, frequency=12)

12번 정답
library(forecast)
fit_arima <- auto.arima(ts_sales)
forecast(fit_arima, h=3)

13번 정답
library(tm)
removeWords("Data science is an exciting and rapidly growing field",
            stopwords("en"))

14번 정답

Cp 계산

𝐶
𝑝
=
𝑈
𝑆
𝐿
−
𝐿
𝑆
𝐿
6
𝜎
=
1
6
×
0.15
=
1.11
Cp=
6σ
USL−LSL
	​

=
6×0.15
1
	​

=1.11

Cpk 계산

𝐶
𝑝
𝑘
=
min
⁡
(
𝑈
𝑆
𝐿
−
𝜇
3
𝜎
,
𝜇
−
𝐿
𝑆
𝐿
3
𝜎
)
=
min
⁡
(
1.11
,
1.11
)
Cpk=min(
3σ
USL−μ
	​

,
3σ
μ−LSL
	​

)=min(1.11,1.11)

해석: 공정능력은 최소 기준은 충족하지만, 우수하다고 보긴 어려움.

15번 정답 (핵심차이)

Accuracy: 전체 중 맞게 분류한 비율

Recall: 실제 긍정(True Positive) 중 모델이 맞춘 비율

해설: 의료·사기탐지처럼 놓치면 안 되는 분야는 Recall이 더 중요.




ADP 실기 모의고사 2회차 (실전 난이도 동일)
📂 사용 데이터셋 (customer2.csv – 아래 그대로 사용 가능)
customer2 <- read.csv(text = "
id,age,income,gender,score,purchase,visits,segment
1,28,3500,F,78,1,5,A
2,42,5200,M,65,0,3,B
3,35,4100,F,82,1,4,A
4,57,6900,M,58,0,2,C
5,31,3800,F,80,1,6,A
6,49,5600,M,62,0,3,B
7,40,4500,F,85,1,5,A
8,52,6400,M,59,0,2,C
9,29,3600,F,77,1,4,A
10,46,5300,M,63,0,3,B
")


변수 설명:

purchase: 구매 여부(1/0)

segment: 고객 세그먼트(A/B/C)

visits: 방문 횟수

📝 모의고사 2회차 문제 (총 15문항)
문제 1. 이상치 처리

income 변수가 박스플롯 기준 이상치가 있는지 R 코드로 판단하라.

문제 2. 파생변수 생성

방문당 점수 효율

𝑠
𝑐
𝑜
𝑟
𝑒
_
𝑒
𝑓
𝑓
=
𝑠
𝑐
𝑜
𝑟
𝑒
𝑣
𝑖
𝑠
𝑖
𝑡
𝑠
score_eff=
visits
score
	​


을 생성하라.

문제 3. 그룹 요약

segment별 평균 income과 평균 score를 계산하라.

문제 4. 교차표 분석

gender와 purchase 간의 관계를 교차표로 요약하라.

문제 5. 카이제곱 검정

위 교차표를 바탕으로 카이제곱 검정을 수행하라.
대립가설: 성별과 구매 여부는 독립이 아니다.

문제 6. 로지스틱 회귀

purchase ~ age + income + score
로 모델을 구성하고, **income의 OR(odds ratio)**를 해석하라.

문제 7. 모델 적합도 평가

위 로지스틱 모델의 AIC를 출력하라.

문제 8. Random Forest 모델

purchase를 예측하기 위한 랜덤포레스트 모델을 생성하고
변수 중요도를 출력하라.

문제 9. 클러스터링

age, income, score 를 사용해 K=3 군집을 수행하고
각 군집의 중심(centroid)을 출력하라.

문제 10. 표준화 후 클러스터 비교

scale()로 표준화한 후 다시 K=3 군집을 수행하라.
표준화 전후 군집 결과가 어떻게 달라지는지 해석하라.

문제 11. PCA

PCA를 수행하고 PC1·PC2가 전체 분산의 몇 %를 설명하는지 구하라.

문제 12. 텍스트 마이닝

다음 문장을 불용어 제거 후 단어 수로 나열하라.

"Customer segmentation improves marketing efficiency"

문제 13. 시계열 – 추세 해석

아래 데이터로 시계열 ts 객체를 생성하고 추세(Trend)를 설명하라.

sales <- c(120,130,150,160,170,200,210,220,240,260,270,300)

문제 14. 관리도 해석

평균=50, σ=2.5 일 때
UCL, LCL을 계산하고 공정 안정성을 논하라.

문제 15. Recall & Precision 비교

Recall과 Precision의 차이를 서술하라.

📘 정답 및 해설 — 모의고사 2회차
1번 정답
boxplot(customer2$income)
boxplot.stats(customer2$income)$out


해설: 이상치 목록이 있으면 outlier 존재.

2번 정답
customer2$score_eff <- customer2$score / customer2$visits

3번 정답
aggregate(cbind(income, score) ~ segment, data=customer2, mean)

4번 정답
table(customer2$gender, customer2$purchase)

5번 정답
chisq.test(table(customer2$gender, customer2$purchase))


해석: p < 0.05이면 성별과 구매 여부는 독립이 아니다.

6번 정답
fit <- glm(purchase ~ age + income + score,
           data=customer2, family="binomial")
exp(coef(fit))


해석 예시:

income의 OR=1.003이라면, income이 1 증가할 때 구매 오즈는 0.3% 증가.

7번 정답
AIC(fit)


AIC가 낮을수록 더 좋은 모델.

8번 정답
library(randomForest)
rf <- randomForest(as.factor(purchase) ~ ., data=customer2, importance=TRUE)
importance(rf)

9번 정답
k <- kmeans(customer2[, c("age","income","score")], centers=3)
k$centers

10번 정답
scaled <- scale(customer2[, c("age","income","score")])
k2 <- kmeans(scaled, centers=3)
k2$centers


해설:

표준화 전: income이 큰 영향을 주는 경향

표준화 후: 세 변수 모두 비슷한 영향력

11번 정답
p <- prcomp(customer2[, c("age","income","score")], scale.=TRUE)
summary(p)


Proportion of Variance 1, 2값 활용.

12번 정답
library(tm)
removeWords("Customer segmentation improves marketing efficiency",
            stopwords("en"))


결과 예시:
"Customer segmentation improves marketing efficiency"
→ "Customer segmentation improves marketing efficiency"
(의미 있는 단어만 남음)

13번 정답
ts_sales <- ts(sales, frequency=12)
plot(decompose(ts_sales))


해석: 전 기간 동안 명확한 우상향 추세 존재.

14번 정답

UCL, LCL 계산:

𝑈
𝐶
𝐿
=
𝜇
+
3
𝜎
=
50
+
7.5
=
57.5
UCL=μ+3σ=50+7.5=57.5
𝐿
𝐶
𝐿
=
𝜇
−
3
𝜎
=
50
−
7.5
=
42.5
LCL=μ−3σ=50−7.5=42.5

해석:

측정값이 모두 42.5~57.5 사이면 공정 안정적

벗어나면 특별원인 존재

15번 정답
개념	정의
Recall	실제 Positive 중 모델이 맞춘 비율
Precision	모델이 Positive라고 예측한 것 중 정답 비율

해설:

Recall은 “놓치지 않는 것”이 중요할 때 (의료, 사기 탐지)

Precision은 “틀리면 안 되는 것”이 중요할 때 (광고 타겟팅)





ADP 실기 모의고사 3회차 (실전 난이도 동일)
📂 사용 데이터셋 (customer3.csv — 아래 그대로 사용 가능)
customer3 <- read.csv(text = "
id,age,income,gender,score,spend,purchase,region,visits
1,26,3400,F,74,300,1,East,4
2,43,5200,M,60,200,0,West,3
3,38,4500,F,82,450,1,South,5
4,55,7000,M,57,180,0,East,2
5,30,3600,F,79,320,1,North,6
6,48,5900,M,63,210,0,West,3
7,41,4800,F,85,500,1,North,5
8,53,6700,M,56,170,0,South,2
9,32,3800,F,76,330,1,East,4
10,46,5400,M,62,205,0,West,3
")


변수 설명:

spend: 구매액

purchase: 구매 여부

score: 고객 점수

visits: 방문 횟수

📝 모의고사 3회차 문제 (총 15문항)
문제 1. 결측치 탐색

모든 변수의 결측치를 확인하는 R 코드를 작성하라.

문제 2. 파생변수 생성

1회 방문당 평균 구매액(단, purchase=1일 때만):

𝑠
𝑝
𝑒
𝑛
𝑑
_
𝑝
𝑒
𝑟
_
𝑣
𝑖
𝑠
𝑖
𝑡
=
𝑠
𝑝
𝑒
𝑛
𝑑
𝑣
𝑖
𝑠
𝑖
𝑡
𝑠
spend_per_visit=
visits
spend
	​

문제 3. 범주형 변수 탐색

region별 purchase 비율(%)을 계산하라.

문제 4. 상관 분석

income, score, spend 간 상관행렬을 구하고 해석하라.

문제 5. 회귀모델

종속변수 spend, 설명변수 age + income + score로 선형회귀모델을 구축하고
score 계수를 해석하라.

문제 6. 선형모델 진단

위 회귀모델에 대해 다중공선성(VIF)을 계산하라.

문제 7. 로지스틱 회귀

purchase를 종속변수로 하고
(age + income + score + visits)를 설명변수로 로지스틱 회귀모델을 만들고,
**visits의 오즈비(OR)**를 해석하라.

문제 8. Decision Tree

purchase 예측을 위한 rpart 모형을 만들고
트리 시각화를 위한 plot 명령을 작성하라.

문제 9. 클러스터 분석

age, income, score, spend 를 기준으로 K=2 군집 분석을 수행하고
두 군집 중심값을 제시하라.

문제 10. 표준화 후 군집 분석

scale() 사용 후 다시 K=2 군집 분석을 수행하고
전과 어떻게 달라지는지 해석하라.

문제 11. PCA

age, income, score, spend 를 대상으로 PCA를 수행하고
PC1이 전체 분산의 몇 %를 설명하는지 구하라.

문제 12. 텍스트 마이닝

아래 문장에서 stopword 제거 후 단어를 나열하라.

"Customer loyalty programs increase repeat purchases and engagement"

문제 13. 시계열 생성 및 시각화

아래 매출 데이터를 ts 객체로 생성하고 추세를 설명하라.

sales <- c(100,120,140,160,180,210,240,260,300,330,360,390)

문제 14. Cp, Cpk 해석

평균=100, 표준편차=4, LSL=92, USL=108일 때
Cp, Cpk를 계산하고 공정 상태를 평가하라.

문제 15. Confusion Matrix 지표 해석

Precision 과 F1-score의 차이를 설명하라.

📘 모범답안 & 해설 — 모의고사 3회차
1번 정답
colSums(is.na(customer3))

2번 정답
customer3$spend_per_visit <- customer3$spend / customer3$visits

3번 정답
prop.table(table(customer3$region, customer3$purchase), 1) * 100


해설: 행 기준 비율 사용.

4번 정답
cor(customer3[, c("income","score","spend")])


해석 예시: spend는 score와 강한 양의 상관.

5번 정답
fit <- lm(spend ~ age + income + score, data=customer3)
summary(fit)


해석 예시(모범답안):

score 계수=3.1이면 점수가 1 증가할 때 평균 구매액은 약 3.1 증가.

6번 정답
library(car)
vif(fit)


VIF>10이면 다중공선성 강함.

7번 정답
model <- glm(purchase ~ age + income + score + visits,
             data=customer3, family="binomial")
exp(coef(model))


해석 예시:

OR(visits)=1.25 → 방문 1회 증가 시 구매 오즈가 25% 상승.

8번 정답
library(rpart)
tree <- rpart(purchase ~ age + income + score + visits,
              data=customer3)
plot(tree)
text(tree)

9번 정답
k <- kmeans(customer3[, c("age","income","score","spend")], centers=2)
k$centers

10번 정답
scaled <- scale(customer3[, c("age","income","score","spend")])
k2 <- kmeans(scaled, centers=2)
k2$centers


해석:

표준화 전: income, spend가 큰 영향을 줌

표준화 후: 모든 변수가 동일 중요도로 작용

11번 정답
p <- prcomp(customer3[, c("age","income","score","spend")], 
            scale.=TRUE)
summary(p)


출력의 PC1 설명력 확인.

12번 정답
library(tm)
removeWords("Customer loyalty programs increase repeat purchases and engagement",
            stopwords("en"))

13번 정답
ts_sales <- ts(sales, frequency=12)
plot(ts_sales)


해석: 명확한 우상향 추세.

14번 정답

Cp:

𝐶
𝑝
=
𝑈
𝑆
𝐿
−
𝐿
𝑆
𝐿
6
𝜎
=
16
24
=
0.67
Cp=
6σ
USL−LSL
	​

=
24
16
	​

=0.67

Cpk:

𝐶
𝑝
𝑘
=
min
⁡
(
108
−
100
3
×
4
,
100
−
92
3
×
4
)
=
min
⁡
(
0.67
,
0.67
)
Cpk=min(
3×4
108−100
	​

,
3×4
100−92
	​

)=min(0.67,0.67)

해석:
→ 공정능력이 매우 부족(Cpk < 1).
→ 개선 필요.

15번 정답
지표	의미
Precision	모델이 Positive라고 예측한 것 중 정답 비율
F1-score	Precision과 Recall의 조화평균

해설: F1-score는 Precision과 Recall의 균형을 평가할 때 사용.



