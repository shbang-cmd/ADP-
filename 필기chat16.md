# Chapter 16. 인공신경망(Artificial Neural Network, ANN) 기초

인공신경망(ANN)은 인간 뇌의 뉴런 구조를 모방한 머신러닝 모델로,  
복잡한 비선형 관계를 학습하는 데 매우 강력한 기법이다.

딥러닝(Deep Learning)의 기초가 되는 핵심 개념으로  
ADP 실기에서도 고급문항에 종종 등장한다.

---

## 📌 16.1 ANN의 기본 개념

ANN은 **입력층(Input layer)** → **은닉층(Hidden layer)** → **출력층(Output layer)**  
의 구조로 되어 있으며, 각 층에는 여러 개의 “뉴런(Neuron)”이 존재한다.

### 뉴런 계산식

\[
z = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b
\]

\[
a = f(z)
\]

- \(w\): 가중치  
- \(b\): 편향  
- \(f\): 활성화 함수  
- \(a\): 뉴런의 출력값  

---

## 📌 16.2 활성화 함수(Activation Function)

활성화 함수는 **비선형성(non-linearity)**을 추가하여  
신경망이 복잡한 패턴을 학습하게 하는 핵심 요소이다.

### 🔹 1) Sigmoid
\[
f(x)=\frac{1}{1+e^{-x}}
\]

- 0~1 사이 확률 출력  
- 로지스틱 회귀와 동일  
- **단점: 기울기 소실(Vanishing Gradient)**

---

### 🔹 2) Tanh
\[
f(x)=\tanh(x)
\]

- 출력 범위: -1 ~ 1  
- Sigmoid보다 학습 효율 좋음  
- 여전히 기울기 소실 문제 존재

---

### 🔹 3) ReLU (Rectified Linear Unit)
\[
f(x)=\max(0, x)
\]

- 현재 딥러닝에서 가장 널리 사용  
- 계산 빠름  
- **기울기 소실 문제 없음**  
- 단점: 뉴런이 죽는 현상(Dead ReLU)

---

### 🔹 4) Softmax
다중 클래스 분류의 출력층에서 사용됨.

\[
Softmax(z_i)=\frac{e^{z_i}}{\sum_j e^{z_j}}
\]

---

## 📌 16.3 신경망의 구조

### 🔸 1) 입력층(Input Layer)
- 데이터의 feature 개수만큼 노드를 둔다.

### 🔸 2) 은닉층(Hidden Layer)
- 모델이 자동으로 중간 표현을 학습하는 부분  
- 은닉층 수가 많아지면 → **Deep Neural Network (DNN)**  

### 🔸 3) 출력층(Output Layer)
- 회귀 → 활성화 함수 없음(또는 linear)  
- 이진 분류 → sigmoid  
- 다중 분류 → softmax  

---

## 📌 16.4 신경망 학습: Forward & Backpropagation

### 🔹 Forward Propagation (순전파)
입력 → 은닉층 → 출력  
순서대로 계산하여 예측값 생성

### 🔹 Backpropagation (역전파)
오차(error)를 계산해 가중치를 업데이트

\[
w := w - \eta \frac{\partial L}{\partial w}
\]

- \(\eta\) : 학습률(Learning Rate)  
- \(L\) : 손실함수

---

## 📌 16.5 손실 함수(Loss Function)

### 🔸 회귀 문제
- MSE (Mean Squared Error)

### 🔸 이진 분류
- Binary Cross Entropy

### 🔸 다중 클래스 분류
- Categorical Cross Entropy

---

## 📌 16.6 최적화 알고리즘(Optimizer)

### 🔹 SGD (Stochastic Gradient Descent)
기본적인 경사하강법  
속도 느림

### 🔹 Momentum
관성을 추가하여 oscillation 감소

### 🔹 RMSProp
각 변수별로 적응적 학습률 적용

### 🔹 Adam (가장 널리 사용)
Momentum + RMSProp 결합  
빠르고 안정적

---

## 📌 16.7 과적합 방지 방법

신경망은 파라미터 수가 매우 많기 때문에  
과적합(overfitting) 문제가 자주 발생한다.

### ✔ 1) Dropout
학습 중 일부 뉴런을 랜덤하게 제거  
→ 과적합 크게 감소

### ✔ 2) L1/L2 정규화(Regularization)
가중치에 패널티 부여

### ✔ 3) Early Stopping
검증 손실 증가 시 학습 중단

### ✔ 4) 데이터 증강(Data Augmentation)
이미지·텍스트에서 많이 사용  
학습 데이터 다양화

---

## 📌 16.8 딥러닝과 ANN의 관계

ANN(고전 신경망)  
→ 은닉층 1~2개

DNN(Deep Neural Network)  
→ 은닉층 수십~수백 개

CNN, RNN, Transformer 등  
모두 ANN에서 발전한 구조이다.

---

## 📌 16.9 실무 활용 분야

- 이미지 분류(CNN)  
- 음성 인식(RNN, LSTM)  
- 기계 번역(Transformer)  
- 추천 시스템(DeepFM, Wide&Deep)  
- 금융 사기 탐지  
- 제조 설비 이상 탐지  
- 텍스트 요약 및 생성(ChatGPT 포함)  

---

# ✔ Chapter 16 요약

- ANN은 입력층 → 은닉층 → 출력층 구조  
- 활성화 함수는 비선형 학습의 핵심  
- 역전파로 가중치 업데이트  
- Adam이 가장 많이 사용되는 옵티마이저  
- Dropout/Early Stopping으로 과적합 방지  
- 딥러닝의 모든 모델은 ANN을 기반으로 발전  



# Chapter 17. 서바이벌 분석(Survival Analysis)

서바이벌 분석(Survival Analysis)은  
**시간의 흐름에 따라 사건(Event)이 발생할 확률을 분석하는 통계 기법**이다.

주요 예:
- 고객 이탈(churn) 시점 분석
- 기계 고장 시간 예측
- 환자 생존 시간 분석
- 보험 청구 시점 예측
- 직원 퇴사 가능성 분석

서바이벌 분석의 핵심은 **시간 정보 + 검열(censoring)**을 다룰 수 있다는 점이다.

---

## 📌 17.1 사건(Event)과 검열(Censoring)

### 🔹 사건(Event)
특정 순간 발생하는 결과  
예: 사망, 고장, 탈퇴, 이탈, 이직

### 🔹 검열(Censoring)
관측 기간이 끝났지만 사건이 **아직 발생하지 않은 상태**

예:
- 고객 관찰 중인데 아직 탈퇴 안 함  
- 기계 고장 없이 관찰 종료  
- 환자가 아직 생존해 있음  

검열이 존재하는 데이터는 일반 회귀 모델로 분석할 수 없으며,  
**서바이벌 분석만이 올바른 추정이 가능**하다.

---

## 📌 17.2 생존함수(Survival Function)

생존함수 S(t)는  
“시간 t까지 사건이 발생하지 않을 확률”을 의미한다.

\[
S(t) = P(T > t)
\]

특징:
- 단조 감소  
- t = 0 → S(0) = 1  
- t 증가 → S(t) 감소  

---

## 📌 17.3 위험함수(Hazard Function)

위험함수 h(t)는  
“t 시점까지 생존한 개체가 그 순간 사건을 겪을 조건부 확률”

\[
h(t) = \frac{f(t)}{S(t)}
\]

직관:
- 특정 시점에서 이벤트가 발생할 ‘순간 위험도’

예:
- 특정 주차에서 고객 이탈 위험
- 특정 시간에서 기계가 고장 날 위험

---

## 📌 17.4 Kaplan-Meier 생존곡선 (KM Curve)

Kaplan-Meier(KM) 추정은  
가장 널리 쓰이는 비모수적 생존함수 추정 방법이다.

### 🔧 계산 방식
\[
S(t) = \prod_{t_i \le t} \left(1 - \frac{d_i}{n_i}\right)
\]

- \( n_i \): 위험 집단(해당 시점까지 살아 있는 사람 수)  
- \( d_i \): 해당 시점에서 사건 발생 수  

### 🔹 특징
- 계단형(stepwise) 그래프  
- 검열 데이터가 반영됨  
- 그룹 간 생존 비교 가능

### 🔹 활용 예
- 치료 A vs 치료 B 생존율 비교  
- VIP 고객 vs 일반 고객 이탈 비교  

---

## 📌 17.5 Log-Rank 검정  
(KM 곡선 비교용)

두 개 이상의 생존곡선을 비교하는 통계적 검정.

- 귀무가설: 두 그룹 생존률 차이 없음  
- 대립가설: 생존률 차이 있음  

의료 연구·고객 이탈 분석에서 매우 자주 사용된다.

---

## 📌 17.6 Cox 비례위험모형 (Cox Proportional Hazards Model)

서바이벌 분석의 핵심 모델.  
시간에 따른 위험률을 선형 예측자로 설명한다.

\[
h(t) = h_0(t) \exp(\beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k)
\]

- \( h_0(t) \): baseline hazard  
- \( \exp(\beta) \): 위험비(Hazard Ratio, HR)

---

### ✔ Hazard Ratio 해석 예시

- HR = 1 → 차이 없음  
- HR = 1.5 → 위험률이 50% 증가  
- HR = 0.7 → 위험률 30% 감소 (보호 효과)

### ✔ Cox 모델의 장점
- baseline hazard 추정 불필요  
- 검열 데이터 자연스럽게 처리  
- 의료·산업·CRM 분야에서 필수 모델

### ✔ 가정
- 비례위험(Proportional Hazards) 가정 필요  
  (두 그룹 위험비가 시간에 따라 일정)

---

## 📌 17.7 생존 분석에서 중요한 지표들

| 지표 | 의미 |
|------|------|
| **Median Survival Time** | 생존함수 S(t)=0.5 되는 시간 |
| **Hazard Ratio** | 위험비(주요 해석 지표) |
| **Survival Probability** | 특정 시점의 생존 확률 |
| **Censoring Rate** | 검열 비율 |

---

## 📌 17.8 실무 활용 사례

### 🔸 고객 분석(Customer Survival)
- 고객이 얼마나 오래 유지되는가?
- 특정 고객군의 이탈 위험 예측

### 🔸 보험 및 금융
- 보험금 청구 시점 분석
- 대출 상환 실패 시점 예측

### 🔸 의료
- 치료법 효과 비교
- 특정 병에서 생존 기간 분석

### 🔸 제조 & IoT
- 기계 고장까지의 시간(MTTF) 분석
- 장비 교체 최적 시점 결정

---

# ✔ Chapter 17 요약

- 서바이벌 분석은 "언제(event)"가 발생하는지를 분석  
- 검열(censoring)을 처리할 수 있는 점이 핵심  
- 생존함수 S(t), 위험함수 h(t) 필수 개념  
- Kaplan-Meier는 비모수적 생존률 추정  
- Cox 모델은 생존 분석의 표준 회귀모형  
- Hazard Ratio는 해석의 핵심 지표  



# Chapter 18. 실험설계(Design of Experiments, DOE)

실험설계(DOE)는 **효율적이고 과학적인 실험 수행을 위한 통계적 방법론**이다.  
최소한의 비용과 최소한의 실험 횟수로 최대한 많은 정보를 얻는 것이 목적이다.

산업·생산·품질관리·과학 실험·A/B 테스트 등 매우 넓은 분야에 활용된다.

---

## 📌 18.1 실험설계 기본 개념

### 🔹 요인(Factor)
결과에 영향을 줄 수 있는 변수  
예: 온도, 압력, 약물 농도, 마케팅 광고 유형

### 🔹 수준(Level)
요인의 가능한 값  
예: 온도(70°C, 90°C), 광고 유형(A, B, C)

### 🔹 처리(Treatment)
요인 수준들의 조합  
예: (온도=90°C, 압력=2bar)

### 🔹 반응(Response)
실험 결과  
예: 제품 강도, 고객 클릭률, 수율, 생존율

---

## 📌 18.2 DOE의 목적

DOE는 단순히 실험을 "하는 것"이 아니라,  
**어떻게 해야 실험의 효율과 정확성을 극대화할 수 있는지**를 연구하는 방법이다.

주요 목적:
- 어떤 요인이 결과에 영향을 미치는지 파악  
- 요인 간 **교호작용(Interaction)** 탐지  
- 최적 조건을 찾기 위한 실험 설계  
- 변동(Noise) 최소화  
- 비용 절감 및 실험 반복 최소화  

---

## 📌 18.3 완전요인실험(Full Factorial Design)

모든 요인(level) 조합을 실험하는 방식.

예:
- 요인 A: 2 수준  
- 요인 B: 3 수준  
→ 총 실험 횟수 = 2 × 3 = 6

### ✔ 장점
- 모든 효과(주효과 + 교호작용) 추정 가능  
- 모델 정확성 높음  

### ❌ 단점
- 요인이 많아지면 실험 횟수 폭증  
- 비용 증가  

---

## 📌 18.4 부분요인실험(Fractional Factorial Design)

전체 실험의 **일부 조합만 선택**하여 효율적으로 실험하는 방법.

예: 2^5 = 32개의 전체 조합 중 8개만 실험

장점:
- 실험 횟수 대폭 감소  
- 비용 절감  
- 초기 탐색에 매우 유용  

단점:
- 일부 교호작용 추정 불가  
- 해석 주의 필요  

---

## 📌 18.5 교호작용(Interaction)

요인들이 단독으로는 특정한 효과를 보이지만,  
여러 요인이 **함께 작용할 때 결과가 달라지는 현상**을 의미한다.

예:  
- 온도 증가 → 품질 상승  
- 습도 증가 → 품질 하락  
- **온도 + 습도 = 예상치 못한 급락**

교호작용은 실험에서 가장 중요한 패턴 중 하나다.

---

## 📌 18.6 난괴법(Randomized Block Design)

실험 대상의 자연스러운 변동(블록)을 고려하여  
그 안에서 실험을 비교하는 방식.

예:
- 농업 실험 → 토양 차이  
- 공정 실험 → 장비 간 차이  
- 마케팅 → 지역 그룹 차이

블록 내 변동은 통제하고,  
요인의 효과만 정확히 측정할 수 있다.

---

## 📌 18.7 중심합성계획(Central Composite Design, CCD)

반응표면분석(RSM)의 핵심 실험 설계 기법.  
최적 조건을 찾기 위한 정교한 실험 설계이다.

구성:
- 요인극단값(High/Low)
- 중심점(center point)
- 별점(axial point)

용도:
- **최적화 문제** 해결  
- 공정의 최적 운영 조건 도출

---

## 📌 18.8 태그치 방법(Taguchi Method)

일본의 태그치 박사가 개발한 **강건설계(Robust Design)** 방법론.

핵심 개념:
- 노이즈(방해요인)를 고려한 설계  
- 품질 변동 최소화  
- SN비(Signal-to-Noise Ratio) 활용  

산업 생산성 향상을 위한 기법으로 제조업에서 많이 사용된다.

---

## 📌 18.9 A/B 테스트 — 현대적 실험설계

웹·마케팅 분야에서는 DOE 개념이  
“A/B Test” 형태로 널리 사용된다.

예:
- 광고 A vs 광고 B의 클릭률 비교  
- 버튼 색상(파랑 vs 빨강)의 전환율 비교  

A/B 테스트는 DOE 중 가장 단순하면서도  
효과적이며 비즈니스에서 가장 널리 쓰인다.

---

## 📌 18.10 DOE 실무 적용 예

### 🔸 제조업
- 공정 조건 최적화  
- 온도·속도·압력에 따른 수율 최적화  

### 🔸 제약·의학
- 약물 조합 최적화  
- 실험군·대조군 비교  

### 🔸 IT/마케팅
- 웹 페이지 요소 실험  
- 사용자 행동 개선 전략  

### 🔸 농업
- 비료·토질·습도 조절 실험  

### 🔸 AI/ML 모델링
- Hyperparameter tuning (Grid Search/Random Search는 DOE의 응용)

---

# ✔ Chapter 18 요약

- DOE는 효율적이고 통계적으로 타당한 실험 설계 방법  
- 기본 요소: 요인, 수준, 반응, 교호작용  
- 완전요인 → 정확하지만 비용 큼  
- 부분요인 → 실험 횟수 절감  
- 난괴법 → 블록 변동 제거  
- CCD → 공정 최적화에 매우 중요  
- A/B 테스트 → DOE의 현대적 형태  



# Chapter 19. 품질관리(Quality Control, QC) & 통계적 공정관리(SPC)

품질관리(QC: Quality Control)와  
통계적 공정관리(SPC: Statistical Process Control)는  
제품·서비스의 품질을 안정적으로 유지하기 위한 통계 기법이다.

핵심 목표:
- 공정에서 발생하는 변동을 파악하고 관리  
- 이상 상태를 조기에 감지  
- 품질 향상을 위한 의사결정 지원  

SPC는 제조업뿐 아니라 금융·IT·서비스·병원 등 다양한 산업에서 활용된다.

---

## 📌 19.1 변동(Variation)의 개념

제품·공정 결과는 항상 변동을 가진다.

### 🔹 1) 공정상 변동(Common Cause Variation)
- 공정 자체의 자연스러운 변동  
- 예측 가능, 관리 불가능  
- 정상적인 공정 상태(Stable Process)

### 🔹 2) 이상 변동(Special Cause Variation)
- 특정 원인으로 발생하는 비정상 변동  
- 예측 불가능, 관리 가능  
- 공정 이상 경보 필요

관리도(Control Chart)는 두 변동을 구분하는 핵심 도구이다.

---

## 📌 19.2 관리도(Control Chart)

관리도는 공정이 안정 상태인지(Statistical Control)를 판단한다.  
가장 핵심적인 SPC 도구이다.

관리도 구성 요소:
- 중심선(Center Line, CL)
- 상한선(UCL: Upper Control Limit)
- 하한선(LCL: Lower Control Limit)
- 데이터 점(측정값)

일반적으로 관리 한계는 ±3σ 기준을 사용한다.

---

## 📌 19.3 관리도 종류 (변수형 / 속성형)

### 🔷 1) 변수형 관리도 (측정 가능한 연속형 데이터)
| 관리도 | 용도 |
|-------|------|
| **X-bar 관리도** | 평균 변화 탐지 |
| **R 관리도** | 범위(Range) 변화 탐지 |
| **S 관리도** | 표준편차 변화 탐지 |

### 🔷 2) 속성형 관리도 (합격/불합격 등 이산형 데이터)
| 관리도 | 용도 |
|--------|------|
| **p 관리도** | 불량품 비율 |
| **np 관리도** | 불량품 개수 |
| **c 관리도** | 단위당 결함 수 |
| **u 관리도** | 기회당 결함 비율 |

ADP 실기에서 자주 등장하므로 반드시 기억해야 하는 관리도 구분이다.

---

## 📌 19.4 X-bar & R 관리도

가장 널리 사용되는 관리도 조합.

- X-bar 관리도 → 평균 변화  
- R 관리도 → 산포(변동) 변화  

두 관리도가 모두 안정적이어야 공정이 관리 상태라고 판단한다.

---

## 📌 19.5 관리도의 이상 신호(Rule Violations)

관리도에서 경보를 발생시키는 주요 규칙:

### ✔ Rule 1  
점 하나가 UCL 또는 LCL을 벗어남 → 즉시 이상

### ✔ Rule 2  
연속 7점 이상 한쪽 방향으로 증가/감소

### ✔ Rule 3  
연속 7점 이상 중심선의 위 또는 아래에만 위치

### ✔ Rule 4  
근접구분(Zone) 기준을 반복적으로 위반

이상 신호가 발생하면 원인 조사를 실시하고 조치를 취해야 한다.

---

## 📌 19.6 공정능력지수(Process Capability Index)

공정이 규격(Specification Limits) 내에서 얼마나 잘 생산되는지를 평가하는 지표.

### 🔸 Cp (Capability Index)

\[
Cp = \frac{USL - LSL}{6\sigma}
\]

- 공정 평균 위치는 고려하지 않음  
- 값이 클수록 공정능력 우수

### 🔸 Cpk (Centered Capability Index)

\[
Cpk = \min\left(\frac{USL - \mu}{3\sigma}, \frac{\mu - LSL}{3\sigma}\right)
\]

- 공정 평균이 중앙에서 벗어난 경우 평가 가능  
- Cp ≥ 1.33이면 일반적으로 양호한 공정  
- Cpk ≥ 1.33도 품질 우수 기준으로 사용됨

---

## 📌 19.7 6시그마(Six Sigma)

6시그마는 품질 목표가 “백만 개 중 3.4개 불량” 수준임을 의미한다.  
DMAIC 절차는 6시그마 개선 프로젝트의 기본 구조이다.

### DMAIC 절차
1. **Define** — 문제 정의  
2. **Measure** — 데이터 측정  
3. **Analyze** — 원인 분석  
4. **Improve** — 개선안 실행  
5. **Control** — 관리 계획 수립  

---

## 📌 19.8 실무 적용 예

### 🔸 제조 공정
- 불량률 모니터링  
- 공정의 평균 및 산포 관리  
- 장비 노후화 감지

### 🔸 금융/IT 서비스
- 시스템 응답시간 품질 관리  
- 서버 트래픽 패턴 감시  

### 🔸 병원/의료 분야
- 감염률 관리  
- 수술 성공률 모니터링  

### 🔸 고객 서비스
- 콜센터 서비스 품질 관리  
- VOC 발생 패턴 분석  

---

# ✔ Chapter 19 요약

- SPC는 공정 변동을 통계적으로 관리하는 기법  
- 관리도는 공정이 안정적인지 판단하는 핵심 도구  
- 변수형(X-bar, R) / 속성형(p, np, c, u) 구분 중요  
- 공정능력 Cp, Cpk ≥ 1.33 → 양호한 공정  
- 6시그마는 DMAIC 절차 기반 품질 개선 방법론  



# Chapter 20. ADP 실기 문제 유형 총정리

ADP 실기 시험은 **데이터 전처리 → 분석 → 모델링 → 평가 → 결과 해석**  
전체 과정을 실제 데이터로 직접 수행하는 시험이다.

출제 비중:
- 데이터 전처리: 35~40%
- 시각화: 10~15%
- 모델링/분석: 25~30%
- 해석 및 보고서 작성: 20%

문제 유형은 크게 4가지로 나눌 수 있다.

---

# 📌 20.1 유형 1: 데이터 전처리 (가장 높은 비중)

ADP 실기에서 가장 많은 비중을 차지하는 영역이다.  
이 영역만 잘해도 합격 가능성이 매우 커진다.

### 🔸 주요 작업
- 결측치 처리 (mean, median, mode, knn, 삭제)
- 이상치 탐지 (IQR, Z-score, boxplot)
- 변수 변환 (log, sqrt, scaling)
- 날짜 변환, 문자열 처리
- 그룹 연산(groupby), 피벗(pivot)
- merge/join 실습
- 파생변수(feature engineering) 생성

### 🔸 예시 문제
- “결측치를 중앙값으로 대체하고 파생변수 3개를 만들어라”
- “이상치를 제거한 후 그룹별 평균을 계산하라”
- “문자열에서 숫자만 추출해 새로운 열을 생성하라”

---

# 📌 20.2 유형 2: 데이터 시각화

주로 matplotlib / seaborn / ggplot2 기반의 시각화를 요구한다.

### 🔸 자주 출제되는 그래프
- 산점도(scatter plot)
- 상자그림(boxplot)
- 히스토그램(histogram)
- 막대그래프(barplot)
- 선그래프(line plot)
- 트리맵(treemap)  
- heatmap

### 🔸 핵심 포인트
- 축 라벨, 제목, 범례 정확히 표기
- 한글 폰트 설정
- 요구된 컬러/조건 정확히 반영
- 특정 구간 강조(limits, geom_vline 등)

---

# 📌 20.3 유형 3: 통계 분석 및 모델링

ADP 실기에서는 통계 + 머신러닝을 모두 요구한다.

### 🔹 회귀 분석
- 단순/다중 회귀
- 회귀 계수 해석
- VIF 기반 다중공선성 확인
- 잔차 분석(정규성, 등분산성)

### 🔹 분류 분석
- 로지스틱 회귀
- 의사결정나무, 랜덤포레스트
- SVM, KNN (가끔 등장)
- 성능 평가: Accuracy, Precision, Recall, F1, ROC-AUC

### 🔹 시계열 분석
- 이동평균, 차분
- AR, MA, ARIMA, SARIMA
- ACF/PACF 그래프 해석

### 🔹 클러스터링
- K-means
- 계층적 군집화
- 실루엣 계수 해석

### 🔹 차원축소
- PCA 주성분 해석
- Scree plot 해석

---

# 📌 20.4 유형 4: 분석 결과 해석 및 보고서 작성

이 영역에서 점수 차이가 많이 발생한다.

### 🔹 자주 요구되는 해석 유형
- 모델의 가장 중요한 변수 설명
- 회귀 계수 해석(양·음, 유의성)
- 분류 모델의 혼동행렬 해석
- KM 생존곡선 비교
- PCA 주성분 의미 해석

### 🔹 보고서 작성 팁
- 문제에서 요구한 항목만 정확히 작성
- 그래프 캡션(설명)을 명확하게
- 통계 지표는 숫자와 함께 해석
- 가설검정 결과는 p-value 기반으로 명확히 제시
- 해석은 ‘원인’이 아니라 ‘관계’에 집중

예:
> X가 증가할 때 Y가 증가하는 경향이 있습니다.  
> (인과가 아니라 패턴 설명)

---

# 📌 20.5 실기 시험에서 자주 나오는 코드 패턴

### 🔸 데이터 읽기 / 처리
```python
df = pd.read_csv("data.csv")
df['new'] = df['col'].astype(int)
df.dropna(inplace=True)


-----------------------------------------------------------------------------------------

20.6 실기 시험 시간 전략

전체 시간: 3시간

문제 수: 7~10문항

데이터 전처리 40분 + 시각화 20분 + 모델링 60~80분

해석 및 보고서 20~30분

남은 시간: 디버깅

✔ 절대적인 전략

에러를 무작정 고치지 말고 코드를 처음부터 다시 입력

그래프는 먼저 rough하게 그린 뒤 세부 조정

모델 튜닝은 기본 파라미터로 먼저 수행

마지막 20분은 오타 잡기

📌 20.7 실기에서 자주 나오는 실수

열 이름 오타

데이터 타입 변환 누락

누락된 한글 폰트 설정

테스트 데이터와 훈련 데이터 혼용

다중공선성 확인 없이 회귀 분석 수행

정규성·등분산성 검정 해석 누락

그래프 라벨/제목 미입력

문제에서 요구한 항목 일부 누락

ADP 실기 채점은 **‘정답 여부 + 과정 명확성’**으로 평가된다.

📌 20.8 실기 합격을 위한 3대 공식
✔ 1) 코드는 단순하게

불필요한 함수/루프는 지양
→ 가독성 + 디버깅 속도 증가

✔ 2) 해석은 문제 요구에 정확히 맞추기

문제 조건에서 벗어나면 감점

✔ 3) 통계 개념 용어 정확히 사용

p-value

유의수준

분산분석

Hazard Ratio

PCA 분산 설명력

✔ Chapter 20 요약

ADP 실기는 전처리 → 시각화 → 분석 → 모델링 → 해석 순으로 출제

결측치/이상치 처리, 파생변수 생성 비중 높음

분류·회귀·시계열·군집 등 폭넓은 모델링 필요

보고서 해석 능력이 점수 차이를 만드는 핵심

시간 배분과 디버깅이 합격의 관건
